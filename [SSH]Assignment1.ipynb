{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[SSH]Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SophieShin/DeepLearning/blob/main/%5BSSH%5DAssignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42CRdtcCRTuc"
      },
      "source": [
        "# Assignment 1 – Polynomial Regression using ``torch.nn.Module``\n",
        "\n",
        "- Please create a copy of this notebook onto your own Drive before working on it: `File-->Save a copy in Drive`\n",
        "- Please submit your ipynb file named with your initials, e.g. `YGM-Assignment1.ipynb` with **the CODE cells output visible** to support your answers and **TEXTUAL answers given as comments** in the code cells.\n",
        "- Deadline for submission is **midnight, Friday, March 18th.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KvsIo2UfwO3"
      },
      "source": [
        "## Neural Network Model for Polynomial Regression\n",
        "Your task is to build a neural network for the function $y = x^2 + 3x$\n",
        "\n",
        "Requirements:\n",
        "- You MUST use `torch.nn.Module` to define your neural network class.\n",
        "- The training data should have **10 input values, $x$, and the correct corresponding output values, $y$,** for the function $y = x^2 + 3x$\n",
        "- The NN may have **maximum TWO hidden layers**.\n",
        "- You may use a **maximum of 500 neuron units in each hidden layer**.\n",
        "- You may train over a **maximum of 1000 epochs**.\n",
        "- Use suitable activation functions that have been covered in class.\n",
        "- You MUST use the **Adam optimiser, `torch.optim.Adam()`** and the **MSE loss function**.\n",
        "- **IMPORTANT:** Your model must have a **LOSS OF LESS THAN 0.01** at the end of training.\n",
        "- **Train your model at least 3 times** to see that the final loss value is stable across all three runs.\n",
        "- Print the loss at every 25th iteration.\n",
        "- Test the model on $x=10$.\n",
        "- **Save your training loss** at every iteration.\n",
        "\n",
        "Note:\n",
        "- If your model does not achieve a loss of less than 0.01, you will still be awarded marks for `Q7 – Q10` as long as you can explain your answers accordingly."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "87Abo5V880G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define training data for a the mathematical formula y = x^2 + 3x (3)\n",
        "\n",
        "x = torch.tensor([\n",
        "                  [0], [1], [2], [3], [4], [5], [6], [7], [8], [9]\n",
        "], dtype = torch.float32)\n",
        "\n",
        "y = torch.tensor([\n",
        "                  [0], [1**2 + 3*1], [2**2 + 3*2], [3**2 + 3*3], [4**2 + 3*4], [5**2 + 3*5], [6**2 + 3*6], [7**2 + 3*7], [8**2 + 3*8], [9**2 + 3*9]\n",
        "], dtype = torch.float32)\n",
        "\n",
        "print(x, '\\n', y)\n",
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Bs6dZ687tU",
        "outputId": "e2bd4be1-2420-4c00-b557-caef691d742d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]]) \n",
            " tensor([[  0.],\n",
            "        [  4.],\n",
            "        [ 10.],\n",
            "        [ 18.],\n",
            "        [ 28.],\n",
            "        [ 40.],\n",
            "        [ 54.],\n",
            "        [ 70.],\n",
            "        [ 88.],\n",
            "        [108.]])\n",
            "torch.Size([10, 1]) torch.Size([10, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Define NN class (10)\n",
        "\n",
        "class MyNN(nn.Module) :\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear1 = nn.Linear(1, 300)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.linear2 = nn.Linear(300, 300)\n",
        "    self.activation2 = nn.ReLU()\n",
        "    self.linear3 = nn.Linear(300,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.linear1(x)\n",
        "    x = self.activation1(x)\n",
        "    x = self.linear2(x)\n",
        "    x = self.activation2(x)\n",
        "    x = self.linear3(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "bSiANE8o-S26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Create an instance of NN model (2)\n",
        "model = MyNN() "
      ],
      "metadata": {
        "id": "uGyWXtVM_DbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Loss and Optimiser (2)\n",
        "\n",
        "learning_rate = 0.01\n",
        "loss_fn = nn.MSELoss() \n",
        "opt = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "yCZbLE0M_LYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 5. Training loop\n",
        "# 5.1 Forward pass (2)\n",
        "# 5.2 Backward pass (3)\n",
        "# 5.3 Print loss every 25th epoch (1)\n",
        "# 5.4 Save training loss at every epoch (2)\n",
        "  \n",
        "# Ensure that loss is less than 0.01 at the end if training consistently (3)\n",
        "\n",
        "training_loss=[]\n",
        "\n",
        "for epoch in range(1000):\n",
        "  y_pred = model(x)\n",
        "  loss = loss_fn(y_pred, y) \n",
        "  training_loss.append(loss.item())\n",
        "\n",
        "  opt.zero_grad()  \n",
        "  loss.backward()\n",
        "  opt.step() \n",
        "\n",
        "  if (epoch+1) % 25 == 0:\n",
        "    print(f'Epoch {epoch+1}/1000, Loss={loss.item():.4f} ')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSM4vLxk_hSq",
        "outputId": "1854290b-293d-4f6c-aaff-5e50948bf8c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/1000, Loss=132.4842 \n",
            "Epoch 50/1000, Loss=18.4808 \n",
            "Epoch 75/1000, Loss=4.6117 \n",
            "Epoch 100/1000, Loss=0.9534 \n",
            "Epoch 125/1000, Loss=0.3130 \n",
            "Epoch 150/1000, Loss=0.1087 \n",
            "Epoch 175/1000, Loss=0.0487 \n",
            "Epoch 200/1000, Loss=0.0468 \n",
            "Epoch 225/1000, Loss=0.0172 \n",
            "Epoch 250/1000, Loss=0.0328 \n",
            "Epoch 275/1000, Loss=0.0155 \n",
            "Epoch 300/1000, Loss=0.0042 \n",
            "Epoch 325/1000, Loss=0.0021 \n",
            "Epoch 350/1000, Loss=0.0132 \n",
            "Epoch 375/1000, Loss=0.0187 \n",
            "Epoch 400/1000, Loss=0.0152 \n",
            "Epoch 425/1000, Loss=0.0027 \n",
            "Epoch 450/1000, Loss=0.0022 \n",
            "Epoch 475/1000, Loss=0.0156 \n",
            "Epoch 500/1000, Loss=0.0142 \n",
            "Epoch 525/1000, Loss=0.0786 \n",
            "Epoch 550/1000, Loss=0.0192 \n",
            "Epoch 575/1000, Loss=0.0391 \n",
            "Epoch 600/1000, Loss=0.0225 \n",
            "Epoch 625/1000, Loss=0.0117 \n",
            "Epoch 650/1000, Loss=0.0057 \n",
            "Epoch 675/1000, Loss=0.0024 \n",
            "Epoch 700/1000, Loss=0.0010 \n",
            "Epoch 725/1000, Loss=0.0004 \n",
            "Epoch 750/1000, Loss=0.0002 \n",
            "Epoch 775/1000, Loss=0.0001 \n",
            "Epoch 800/1000, Loss=0.0013 \n",
            "Epoch 825/1000, Loss=0.0604 \n",
            "Epoch 850/1000, Loss=0.0076 \n",
            "Epoch 875/1000, Loss=0.0141 \n",
            "Epoch 900/1000, Loss=0.0678 \n",
            "Epoch 925/1000, Loss=0.0073 \n",
            "Epoch 950/1000, Loss=0.0075 \n",
            "Epoch 975/1000, Loss=0.0347 \n",
            "Epoch 1000/1000, Loss=0.0008 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_loss[:4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f9cNvmCC6JT",
        "outputId": "594cb10c-1866-4063-8ff3-50dfd6c4c2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2971.97412109375, 1495.0894775390625, 314.3625183105469, 321.93585205078125]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Visualize (3)\n",
        "# Plot the landscape of your training loss (MSE loss) saved for every epoch.\n",
        "# y-axis would mean MSE loss and x-axis would mean the epoch of your training.\n",
        "# Hint: you should plot (1,first MSE loss), ... ,(last epoch number,last MSE loss)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "x_range = np.linspace(1,1000,1000)\n",
        "plt.title('MSE Loss over epoch')\n",
        "plt.plot(x_range.tolist(), training_loss)\n",
        "plt.xlabel('Number of Epoch')\n",
        "plt.ylabel('MSE Loss')\n"
      ],
      "metadata": {
        "id": "xXWhlxrmLBSl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "0823f635-ba02-4241-c24c-1e553d322cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'MSE Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zatxfhYejeB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45b06c99-8a03-4843-9ca0-3bade182b1b4"
      },
      "source": [
        "# 7. Prediction (2)\n",
        "# Let's use the model on a new number x, defined as a tensor\n",
        "\n",
        "# Get the model's prediction for this new x\n",
        "\n",
        "test = torch.tensor([10], dtype = torch.float32)\n",
        "print(model(test).item())\n",
        "print(10**2 + 10*3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127.96083068847656\n",
            "130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvmHgY1oDLiB"
      },
      "source": [
        "# Make sure the output of your code cells support your answers below:\n",
        "\n",
        "# Q8. Describe how the loss changed over time during training. (2)\n",
        "# A8. MSE Loss decreses over time as the number of epoch increases.\n",
        "\n",
        "# Q9. Is the prediction for x=10 close enough to the ideal value of 130? \n",
        "# Why do you think the prediction is or isn't close enough to the ideal value? (2)\n",
        "# A09. The predicted value is not quite close to the actual value. I think the trained model is over-fitted. \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Q10. What are the predictions for x=20 and x=100? Based on these predictions, \n",
        "# comment on whether the model has captured the relationship between the training inputs and outputs. (2)\n",
        "\n",
        "test = torch.tensor([20], dtype = torch.float32)\n",
        "print(model(test).item())\n",
        "print(20**2 + 20*3)\n",
        "print('\\n')\n",
        "\n",
        "test = torch.tensor([100], dtype = torch.float32)\n",
        "print(model(test).item())\n",
        "print(100**2 + 100*3)\n",
        "\n",
        "# A10. The model seems over-fitted since it does not capture out-of-sample relationship,\n",
        "# because if I test with bigger number, the loss gets bigger."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JDKWZW7E4j9",
        "outputId": "3027ce65-3770-420c-c1ad-6ef885ea52e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322.8564758300781\n",
            "460\n",
            "\n",
            "\n",
            "1770.12158203125\n",
            "10300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q11. Apart from tweaking the number of epochs and the number of neuron units in the hidden layer, think\n",
        "# of AT LEAST ONE more thing you would do to try to improve the model. You do NOT have to follow the \n",
        "# requirements nor to implement anything. (1)\n",
        "\n",
        "# A.11. I think providing wide range of inputs would increase the test accuracy.\n",
        "# The original training data were so dense ranging from 0 to 9.\n",
        "# Also, decreasing the number of epoch would be another way of improving the model.\n"
      ],
      "metadata": {
        "id": "falsoyRnFEwK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}